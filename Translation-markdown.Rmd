---
title: "Translate a dataset of string data using the Google Cloud Translation"
author: "Yannis Chourdakis"
date: "26/04/2020"
output:
  html_document: default
  pdf_document: default
geometry: margin=1in
fontfamily: mathpazo
fontsize: 11pt
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
packages <- c("googleLanguageR", "cld2", "textcat","tidyverse", "datasets")
install.packages(packages, repos = 'http://cran.us.r-project.org')
lapply(packages, require, character.only=TRUE)
```


## First step: Google Translation API authorisation

*(read more about access to Google services through APIs  [here](https://cran.r-project.org/web/packages/gargle/vignettes/get-api-credentials.html))*. 

Your .json authorisation file should be copied in your working directory for R to be able to call it. We will call it later in the ```gl_auth()``` function


## Second step: Getting and preparing the string data

Here we use the ```sentences``` dataset of the ```datasets``` package.


```{r}
str(sentences)
```

```{r}
head(sentences)
```

In case the words were not capitalised, the following function capitalises the first letter of each sentence of the string data:

```{r}
first_letter_upper=function(x) ifelse(is.na(x)==TRUE, NA, paste0(toupper(substr(x, 1, 1)), tolower(substring(x, 2))))
```

Let's clean the string data to prepare it for the translation:

```{r}
sentences_new <- sentences %>% 
  sapply(., str_trim) %>%
  sapply(., str_squish) %>%
  sapply(., first_letter_upper) %>%
  na.omit %>%
  data.frame(stringsAsFactors = FALSE)
```
(*If your dataset has multiple columns you may use ```lapply()``` instead of ```sapply()```*)


## Third step: Kick-off by detecting the language of the existing data:

```{r}
detected_language <- sentences_new %>% sapply(., map_chr, detect_language) %>% data.frame
```

Let's annotate the ones that will be translated during our process in order to know which elements were translated by us:

*(here we translate every element thus we expect all of them to be annotated)*

```{r}
#for (i in 1:ncol(sentences_new)){
  for (k in 1:nrow(sentences_new)){
    sentences_new[k,][detected_language[k,] =="en"] <- 
      paste("(Translated)", sentences_new[k,][detected_language[k,] =="en"], sep = " ")
    }
#}
```
(*If the object sentences_new had multiple columns we would need to uncomment the outer for-loop)*)

## Ready to initiate the translation!
*All sentences are in english therefore we choose to translate them to Italian. Note that this step will need a fair amount of time to execute*

```{r message=FALSE, warning=FALSE,}
gl_auth("google_api_auth.json")

for (i in 1:ncol(sentences_new)){
  sentences_new[,i][detected_language[,i] =="en" & !is.na(detected_language[,i])] <- 
    data.frame(
      gl_translate(
        sentences_new[,i][detected_language[,i] =="en" & !is.na(detected_language[,i])], target = "it"
        )
      )[,1]
  
  sentences_new[,i][sentences_new[,i] %in% c("NA", "N/a", "N/A", "Na", "na", "n/a", "not applicable")] <- NA
  }

head(sentences_new)
```

## Success!
